[
  {
    "objectID": "blog-listing.html",
    "href": "blog-listing.html",
    "title": "Jordan Alfano Insightful Analytics",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n         \n          Author\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n  \n\n\n\n\nRestaurants\n\n\n\n\n\n\n\n\n\nDec 8, 2023\n\n\nJordan Alfano\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nBeer Markets\n\n\n\n\n\n\n\n\n\nNov 2, 2023\n\n\nByeong-Hak Choe\n\n\n2 min\n\n\n\n\n\n\n  \n\n\n\n\nPost With Code\n\n\n\n\n\n\n\n\n\nOct 30, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\n\n\nOct 27, 2023\n\n\nYOUR NAME\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Jordan Alfano",
    "section": "",
    "text": "I am a Sophomore candidate for a Bachelors in Data Analytics at SUNY Geneseo. I enjoy going to the gym on my free time. When I am not doing work or have to taken on a multitude of responsibilities, my time is spent with my family and friends."
  },
  {
    "objectID": "index.html#education",
    "href": "index.html#education",
    "title": "Jordan Alfano",
    "section": "Education",
    "text": "Education\nState University of New York at Geneseo | Geneseo, NY  B.S. in Data Analytics | Aug 2022 - May 2026"
  },
  {
    "objectID": "index.html#experience",
    "href": "index.html#experience",
    "title": "Jordan Alfano",
    "section": "Experience",
    "text": "Experience\nAccenture Data Analyst Virtual Internship"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html",
    "href": "posts/beer-markets/beer-markets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let‚Äôs analyze the beer_data data:\n\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\nrmarkdown::paged_table(beer_data)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "href": "posts/beer-markets/beer-markets.html#variable-description-for-beer_data-data.frame",
    "title": "Beer Markets",
    "section": "Variable Description for beer_data data.frame",
    "text": "Variable Description for beer_data data.frame\nThe following describes the variables in the beer_data data.frame.\n\nhh: Household identifier\n_purchase_desc: Description of the purchase\nquantity: The quantity of beer purchased\nbrand: The brand of beer\ndollar_spent: The amount spent\nbeer_floz: Fluid ounces of beer\nprice_per_floz: Price per fluid ounce\ncontainer: Type of container\npromo: Whether the purchase was on promotion\nmarket: The market where the purchase was made\nDemographics: age, employment status, degree, class of worker (cow), race, and household information like microwave, dishwasher, tvcable, singlefamilyhome, and npeople (number of people in the household)"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "href": "posts/beer-markets/beer-markets.html#purchase-patterns",
    "title": "Beer Markets",
    "section": "Purchase Patterns",
    "text": "Purchase Patterns\nWe‚Äôll explore the purchase patterns in the dataset. This includes understanding the most popular brands, the average quantity purchased, and spending habits across different markets. Here are some specific analyses we can perform:\n\nCalculate the total quantity and spending for each brand.\nFind the average quantity purchased and average spending per purchase.\nCompare the total spending across different markets.\n\nI‚Äôll begin with these analyses and create visualizations to help us understand the data better. Let‚Äôs start by calculating the total quantity and spending for each brand.\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Reading the CSV file\nbeer_data = pd.read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\n# Setting up the visualisation settings\nsns.set(style=\"whitegrid\")\n\n# Calculate total quantity and spending for each brand\nbrand_summary = beer_data.groupby('brand').agg({'quantity':'sum', 'dollar_spent':'sum'}).reset_index()\n\n# Sort by total quantity and spending\nbrand_summary_sorted_quantity = brand_summary.sort_values('quantity', ascending=False)\nbrand_summary_sorted_spent = brand_summary.sort_values('dollar_spent', ascending=False)\n\n\n# Plotting total quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=brand_summary_sorted_quantity, palette='viridis')\nplt.title('Total Quantity of Beer Purchased by Brand')\nplt.xlabel('Total Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting total spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=brand_summary_sorted_spent, palette='viridis')\nplt.title('Total Spending on Beer by Brand')\nplt.xlabel('Total Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar charts above display the total quantity of beer purchased and the total spending by brand. From the looks of it, certain brands dominate in terms of quantity sold and total spending, indicating their popularity.\nNow, let‚Äôs calculate the average quantity purchased and average spending per purchase. For this, we‚Äôll consider each row in the dataset as a separate purchase and compute the averages accordingly.\n\n# Calculate average quantity purchased and average spending per purchase\naverage_purchase = beer_data.groupby('brand').agg({\n    'quantity': 'mean', \n    'dollar_spent': 'mean'\n}).reset_index()\n\n# Sort by average quantity and average spending\naverage_purchase_sorted_quantity = average_purchase.sort_values('quantity', ascending=False)\naverage_purchase_sorted_spent = average_purchase.sort_values('dollar_spent', ascending=False)\n\n# Plotting average quantity for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='quantity', y='brand', data=average_purchase_sorted_quantity, palette='viridis')\nplt.title('Average Quantity of Beer Purchased by Brand')\nplt.xlabel('Average Quantity')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n# Plotting average spending for each brand\nplt.figure(figsize=(10, 8))\nsns.barplot(x='dollar_spent', y='brand', data=average_purchase_sorted_spent, palette='viridis')\nplt.title('Average Spending on Beer by Brand')\nplt.xlabel('Average Spending')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe visualizations above depict the average quantity of beer purchased per brand and the average spending per brand. This shows which brands tend to be bought in larger quantities on average and which brands tend to have higher spending per purchase, which could be indicative of their price point or the purchase of premium products.\nNext, we‚Äôll look at the total spending across different markets to see if there are any notable differences in spending habits geographically. To do this, we‚Äôll sum up the spending in each market and visualize it.\n\n# Calculate total spending in each market\nmarket_spending_summary = beer_data.groupby('market').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nmarket_spending_summary_sorted = market_spending_summary.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending in each market\nplt.figure(figsize=(12, 10))\nsns.barplot(x='dollar_spent', y='market', data=market_spending_summary_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Market')\nplt.xlabel('Total Spending')\nplt.ylabel('Market')\nplt.show()\n\n\n\n\nThe bar chart illustrates the total spending on beer by market, showcasing the differences in spending habits across various regions. Some markets have significantly higher spending, which could be due to a variety of factors including market size, consumer preferences, or economic factors.\nNow, let‚Äôs move on to the second analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "href": "posts/beer-markets/beer-markets.html#demographic-analysis",
    "title": "Beer Markets",
    "section": "Demographic Analysis",
    "text": "Demographic Analysis\nWe will examine which demographics are buying what kind of beer and whether spending habits vary by demographics such as age, employment, and race. For this, we could look at:\n\nSpending by age group\nSpending by employment status\nSpending by race\n\nI‚Äôll start by analyzing spending by age group.\n\n# Calculate total spending by age group\nage_group_spending = beer_data.groupby('age').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nage_group_spending_sorted = age_group_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by age group\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='age', data=age_group_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Age Group')\nplt.xlabel('Total Spending')\nplt.ylabel('Age Group')\nplt.show()\n\n\n\n\nThe bar chart demonstrates the total spending on beer segmented by age group, highlighting which age groups spend the most on beer. It appears that certain age groups are more dominant in beer spending, which may align with the purchasing power or preferences of those groups.\nNext, we will examine spending by employment status.\n\n# Calculate total spending by employment status\nemployment_spending = beer_data.groupby('employment').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nemployment_spending_sorted = employment_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by employment status\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='employment', data=employment_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Employment Status')\nplt.xlabel('Total Spending')\nplt.ylabel('Employment Status')\nplt.show()\n\n\n\n\nThe visualization shows the total spending on beer by employment status. We can see that certain employment groups, such as full-time workers, are spending more on beer, which might be related to their disposable income.\nFinally, let‚Äôs look at spending by race to complete the demographic analysis.\n\n# Calculate total spending by race\nrace_spending = beer_data.groupby('race').agg({'dollar_spent':'sum'}).reset_index()\n\n# Sort by total spending\nrace_spending_sorted = race_spending.sort_values('dollar_spent', ascending=False)\n\n# Plotting total spending by race\nplt.figure(figsize=(10, 6))\nsns.barplot(x='dollar_spent', y='race', data=race_spending_sorted, palette='viridis')\nplt.title('Total Spending on Beer by Race')\nplt.xlabel('Total Spending')\nplt.ylabel('Race')\nplt.show()\n\n\n\n\nThe bar chart above indicates the total spending on beer broken down by race, highlighting which racial groups account for the most beer spending within the dataset. This could reflect both the demographics of the regions where the data was collected and cultural preferences regarding beer.\nNow, let‚Äôs proceed to the third analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "href": "posts/beer-markets/beer-markets.html#price-sensitivity",
    "title": "Beer Markets",
    "section": "Price Sensitivity",
    "text": "Price Sensitivity\nWe‚Äôll look at the price per fluid ounce and see if there are any trends or correlations with the quantity purchased or the brand popularity. To do this, we‚Äôll calculate the average price per fluid ounce for each brand and then visualize how this relates to the average quantity purchased and the total quantity purchased by brand.\nFirst, let‚Äôs calculate the average price per fluid ounce for each brand.\n\n# Calculate average price per fluid ounce for each brand\nbrand_price_sensitivity = beer_data.groupby('brand').agg({\n    'price_per_floz': 'mean', \n    'quantity': 'sum'\n}).reset_index()\n\n# Sort by price per fluid ounce\nbrand_price_sensitivity_sorted = brand_price_sensitivity.sort_values('price_per_floz', ascending=True)\n\n# Plotting average price per fluid ounce for each brand and the total quantity purchased\nfig, ax1 = plt.subplots(figsize=(12, 10))\n\ncolor = 'tab:red'\nax1.set_xlabel('Brand')\nax1.set_ylabel('Average Price per Fluid Ounce', color=color)\nax1.bar(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['price_per_floz'], color=color)\nax1.tick_params(axis='y', labelcolor=color)\nax1.set_xticklabels(brand_price_sensitivity_sorted['brand'], rotation=90)\n\nax2 = ax1.twinx()  # instantiate a second axes that shares the same x-axis\ncolor = 'tab:blue'\nax2.set_ylabel('Total Quantity Purchased', color=color)  # we already handled the x-label with ax1\nax2.plot(brand_price_sensitivity_sorted['brand'], brand_price_sensitivity_sorted['quantity'], color=color)\nax2.tick_params(axis='y', labelcolor=color)\n\nfig.tight_layout()  # otherwise the right y-label is slightly clipped\nplt.title('Average Price per Fluid Ounce & Total Quantity Purchased by Brand')\nplt.show()\n\n\n\n\nIn the visualization, we have a bar graph showing the average price per fluid ounce for each brand (in red) and a line graph showing the total quantity purchased for each brand (in blue). This gives us a sense of whether there‚Äôs a relationship between the price and the quantity purchased. The x-axis labels are quite compressed due to the number of brands, but we can still observe trends such as whether lower-priced beers tend to be purchased in larger quantities.\nLastly, let‚Äôs move to the fourth analysis:"
  },
  {
    "objectID": "posts/beer-markets/beer-markets.html#promotional-impact",
    "href": "posts/beer-markets/beer-markets.html#promotional-impact",
    "title": "Beer Markets",
    "section": "Promotional Impact",
    "text": "Promotional Impact\nWe‚Äôll assess the impact of promotions on the quantity of beer purchased. For this analysis, we can calculate the average quantity purchased with and without promotions and visualize the difference. We‚Äôll do this for each brand to see which brands are most affected by promotions.\nLet‚Äôs begin this analysis by looking at the average quantity purchased with and without promotions for each brand.\n\n# Calculate average quantity purchased with and without promotions for each brand\npromo_impact = beer_data.groupby(['brand', 'promo']).agg({'quantity':'mean'}).reset_index()\n\n# Pivot the data to have promo and non-promo side by side for each brand\npromo_impact_pivot = promo_impact.pivot(index='brand', columns='promo', values='quantity').reset_index()\npromo_impact_pivot.columns = ['brand', 'non_promo', 'promo']\n\n# Calculate the difference in average quantity purchased between promo and non-promo\npromo_impact_pivot['promo_impact'] = promo_impact_pivot['promo'] - promo_impact_pivot['non_promo']\n\n# Sort by the impact of promo\npromo_impact_pivot_sorted = promo_impact_pivot.sort_values('promo_impact', ascending=False)\n\n# Plotting the difference in average quantity purchased between promo and non-promo for each brand\nplt.figure(figsize=(12, 10))\nsns.barplot(x='promo_impact', y='brand', data=promo_impact_pivot_sorted, palette='viridis')\nplt.title('Impact of Promotions on Average Quantity Purchased by Brand')\nplt.xlabel('Difference in Average Quantity Purchased (Promo - Non-Promo)')\nplt.ylabel('Brand')\nplt.show()\n\n\n\n\nThe bar chart illustrates the impact of promotions on the average quantity of beer purchased by brand. A positive value indicates that, on average, more beer is purchased when there is a promotion compared to when there isn‚Äôt. Some brands appear to be significantly more influenced by promotions, with customers buying more when the products are on sale or promotion.\nThis comprehensive analysis has provided insights into purchase patterns, demographic preferences, price sensitivity, and the impact of promotions on beer purchases."
  },
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Post With Code",
    "section": "",
    "text": "This is a post with executable code.\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "posts/starwars/starwars_df.html",
    "href": "posts/starwars/starwars_df.html",
    "title": "Starwars",
    "section": "",
    "text": "Let‚Äôs analyze the starwars data:\nstarwars &lt;- read_csv(\"https://bcdanl.github.io/data/starwars.csv\")"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "href": "posts/starwars/starwars_df.html#variable-description-for-starwars-data.frame",
    "title": "Starwars",
    "section": "Variable Description for starwars data.frame",
    "text": "Variable Description for starwars data.frame\nThe following describes the variables in the starwars data.frame.\n\nfilms List of films the character appeared in\nname Name of the character\nspecies Name of species\nheight Height (cm)\nmass Weight (kg)\nhair_color, skin_color, eye_color Hair, skin, and eye colors\nbirth_year Year born (BBY = Before Battle of Yavin)\nsex The biological sex of the character, namely male, female, hermaphroditic, or none (as in the case for Droids).\ngender The gender role or gender identity of the character as determined by their personality or the way they were programmed (as in the case for Droids).\nhomeworld Name of homeworld"
  },
  {
    "objectID": "posts/starwars/starwars_df.html#human-vs.-droid",
    "href": "posts/starwars/starwars_df.html#human-vs.-droid",
    "title": "Starwars",
    "section": "Human vs.¬†Droid",
    "text": "Human vs.¬†Droid\n\nggplot(data = \n         starwars %&gt;% \n         filter(species %in% c(\"Human\", \"Droid\"))) +\n  geom_boxplot(aes(x = species, y = mass, \n                   fill = species),\n               show.legend = FALSE)"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn‚Äôt specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "project.html",
    "href": "project.html",
    "title": "DANL Project",
    "section": "",
    "text": "Introduction: This project matters because it affected the rate at which people are contracting and healing from the COVID 19 virus at a daily rate. There is a greater amount of people who are recovering compared to the people who are dying.\nData Summary: Our data visualization entails how both death and recovered are increasing at an exponential rate. This provides the assumption that while many may be dying there are more people recovering. In the real world this provides hope for those who are suffering from the virus..\nThis is our R set up. In order to demo certain data we need to go into our library and import the packages we will need order to proceed with this project. The example our case is demonstrated below.\nWe need to assign a name to the data frame that we will be using and copy the path name of the github repository that we will be using in this project. Jocelyn‚Äôs repository is exemplified below.\nday_wise &lt;- read_csv('https://jem10126.github.io/day_wise.csv')\nnvars &lt;- format(round(ncol(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\")\nHere is the paged table using rmarkdown::paged_table() with the results = 'asis' chunk option.\nrmarkdown::paged_table(day_wise)\nData Visualization: We created a ggplot figure in order for us to see exactly how the relationship between amount of deaths and recoveries intertwinds with one another. My group and I decided that a line plot would be of best fit because line plots are useful to track changes over short and long periods of time.\nday_wise %&gt;% \n  ggplot(aes(x = log(Deaths), \n             y = log(Recovered))) + \n  geom_point(alpha = .1, color = 'purple') +\n  geom_smooth(method = lm, se = F) +\n  theme_bw() +\n  theme(legend.position = 'top')\nData Transformation: We used the group by function here in order to group rows that have the same values into summary rows, which then allows us to use the function summary, in order to summarize the statistics provided.\nday_wise &lt;- day_wise %&gt;% \n  group_by(Deaths, Recovered) %&gt;% \n  summarise(Recovered_tot = sum(Recovered, na.rm = T),\n            Deaths_mean = round(mean(Deaths, na.rm = T), 2),\n            .groups = \"drop\")"
  },
  {
    "objectID": "project.html#summary-statistics",
    "href": "project.html#summary-statistics",
    "title": "DANL Project",
    "section": "2.1 Summary Statistics",
    "text": "2.1 Summary Statistics\n\nmpg &lt;- ggplot2::mpg\n\n\n\n\n  \n\n\n\nskim(mpg) %&gt;% \n  select(-n_missing)\n\n\nData summary\n\n\nName\nmpg\n\n\nNumber of rows\n234\n\n\nNumber of columns\n11\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\ncharacter\n6\n\n\nnumeric\n5\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: character\n\n\n\nskim_variable\ncomplete_rate\nmin\nmax\nempty\nn_unique\nwhitespace\n\n\n\n\nmanufacturer\n1\n4\n10\n0\n15\n0\n\n\nmodel\n1\n2\n22\n0\n38\n0\n\n\ntrans\n1\n8\n10\n0\n10\n0\n\n\ndrv\n1\n1\n1\n0\n3\n0\n\n\nfl\n1\n1\n1\n0\n5\n0\n\n\nclass\n1\n3\n10\n0\n7\n0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ndispl\n1\n3.47\n1.29\n1.6\n2.4\n3.3\n4.6\n7\n‚ñá‚ñÜ‚ñÜ‚ñÉ‚ñÅ\n\n\nyear\n1\n2003.50\n4.51\n1999.0\n1999.0\n2003.5\n2008.0\n2008\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñá\n\n\ncyl\n1\n5.89\n1.61\n4.0\n4.0\n6.0\n8.0\n8\n‚ñá‚ñÅ‚ñá‚ñÅ‚ñá\n\n\ncty\n1\n16.86\n4.26\n9.0\n14.0\n17.0\n19.0\n35\n‚ñÜ‚ñá‚ñÉ‚ñÅ‚ñÅ\n\n\nhwy\n1\n23.44\n5.95\n12.0\n18.0\n24.0\n27.0\n44\n‚ñÖ‚ñÖ‚ñá‚ñÅ‚ñÅ"
  },
  {
    "objectID": "project.html#mpg-and-a-type-of-cars",
    "href": "project.html#mpg-and-a-type-of-cars",
    "title": "DANL Project",
    "section": "2.2 MPG and a Type of Cars",
    "text": "2.2 MPG and a Type of Cars\nThe following boxplot shows how the distribution of highway MPG (hwy) varies by a type of cars (class) üöô üöö üöê.\n\nggplot(data = mpg) +\n  geom_boxplot(aes(x = class, y = hwy, fill = class),\n               show.legend = F) +\n  labs(x = \"Class\", y = \"Highway\\nMPG\")"
  },
  {
    "objectID": "quarto-template.html",
    "href": "quarto-template.html",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "",
    "text": "ggplot(diamonds, aes(carat, price)) + \n  geom_hex()\n\n\n\nggsave(\"diamonds.png\") # to save ggplot as a png file.\nwrite_csv(diamonds, \"diamonds.csv\") # to save data.frame as a csv file\noj &lt;- read_csv('https://bcdanl.github.io/data/dominick_oj.csv')\nnvars &lt;- format(round(ncol(oj), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(oj), 0), \n                nsmall=0, \n                big.mark=\",\")\nThe number of variables is 4; the number of observations is 28,947.\nRoses are red\nviolets are blue."
  },
  {
    "objectID": "quarto-template.html#data-summary",
    "href": "quarto-template.html#data-summary",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.1 Data Summary",
    "text": "2.1 Data Summary\n\nSummary statistics (Use skimr::skim())"
  },
  {
    "objectID": "quarto-template.html#data-visualization",
    "href": "quarto-template.html#data-visualization",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.2 Data Visualization",
    "text": "2.2 Data Visualization\n\noj %&gt;% \n  ggplot(aes(x = log(sales), \n             y = log(price),\n             color = brand)) +\n  geom_point(alpha = .1) +\n  geom_smooth(method = lm, se = F) +\n  facet_wrap(.~ad) +\n  theme_bw() +\n  theme(legend.position = 'top')"
  },
  {
    "objectID": "quarto-template.html#data-transformation",
    "href": "quarto-template.html#data-transformation",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.3 Data Transformation",
    "text": "2.3 Data Transformation\n\nob_sum1 &lt;- oj %&gt;% \n  group_by(brand, ad) %&gt;% \n  summarise(sales_tot = sum(sales, na.rm = T),\n            price_mean = round(mean(price, na.rm = T), 2))"
  },
  {
    "objectID": "quarto-template.html#analysis",
    "href": "quarto-template.html#analysis",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.4 Analysis",
    "text": "2.4 Analysis"
  },
  {
    "objectID": "quarto-template.html#quotes",
    "href": "quarto-template.html#quotes",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.5 Quotes",
    "text": "2.5 Quotes\n\nQuote with &gt;\n\n\n‚ÄúThe truth is rarely pure and never simple.‚Äù\n‚Äî Oscar Wilde"
  },
  {
    "objectID": "quarto-template.html#inserting-figures",
    "href": "quarto-template.html#inserting-figures",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.6 Inserting Figures",
    "text": "2.6 Inserting Figures\nFor a demonstration of a DANL tiger, see Figure¬†1.\n\n\n\n\n\nFigure¬†1: DANL Tiger"
  },
  {
    "objectID": "quarto-template.html#inserting-a-html-page",
    "href": "quarto-template.html#inserting-a-html-page",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.7 Inserting a HTML page",
    "text": "2.7 Inserting a HTML page"
  },
  {
    "objectID": "posts/restaurant/restaurants.html",
    "href": "posts/restaurant/restaurants.html",
    "title": "Restaurants",
    "section": "",
    "text": "Let‚Äôs analyze the res data:\n\nres &lt;- read_csv(\"https://bcdanl.github.io/data/DOHMH_NYC_Restaurant_Inspection.csv\")\n\nrmarkdown::paged_table(res)"
  },
  {
    "objectID": "posts/beer-markets/beermarkets.html",
    "href": "posts/beer-markets/beermarkets.html",
    "title": "Beer Markets",
    "section": "",
    "text": "Let‚Äôs analyze the beer_data data:\n\nbeer_data &lt;- read_csv(\"https://bcdanl.github.io/data/beer_markets.csv\")\n\nrmarkdown::paged_table(beer_data)"
  },
  {
    "objectID": "untitled.html",
    "href": "untitled.html",
    "title": "Classwork_10",
    "section": "",
    "text": "billboard &lt;- read_csv(‚Äòhttps://bcdanl.github.io/data/billboard.csv‚Äô)\nQ1a.) Describe how the distribution of rating varies across week 1, week 2, and week 3 using the faceted histogram.\nQ1b.) Which artist(s) have the most number of tracks in billboard data.frame?\nDo not double-count an artist‚Äôs tracks if they appear in multiple weeks.\nQuestion 2 - Average Personal Income in NY Counties The following data is for Question 2:\nny_pincp &lt;- read_csv(‚Äòhttps://bcdanl.github.io/data/NY_pinc_wide.csv‚Äô)\nQ2a Make ny_pincp longer.\nQ2b Provide both (1) ggplot code and (2) a simple comment to describe how overall the yearly trend of NY counties‚Äô average personal incomes are.\nQuestion 3 - COVID-19 Cases The following data is for Question 3:\ncovid &lt;- read_csv(‚Äòhttps://bcdanl.github.io/data/covid19_cases.csv‚Äô)\nQ3a Keep only the following three variables, date, countriesAndTerritories, and cases.\nThen make a wide-form data.frame of covid whose variable names are from countriesAndTerritories and values are from cases.\nThen drop the variable date.\nQ3b Use the wide-form data.frame of covid to find the top 10 countries in terms of the correlation between their cases and the USA case. Use cor(data.frame), which returns a matrix. Then convert it to data.frame using as.data.frame(matrix) ‚Äî"
  },
  {
    "objectID": "spotify all.html",
    "href": "spotify all.html",
    "title": "spotifyall",
    "section": "",
    "text": "---\ntitle: ‚Äúspotifyall‚Äù\nauthor: ‚ÄúJordan Alfano‚Äù\ndate: ‚Äú2023-12-08‚Äù\ncategories: [spotifyall, code, analysis]\nimage: ‚Äúimage.png‚Äù\nexecute:\nwarning: false\nmessage: false\ntoc: true\n---\n```{r}\n#| include: false\nlibrary(knitr)\nlibrary(rmarkdown)\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\nlibrary(hrbrthemes)\ntheme_set(theme_ipsum()+\ntheme(strip.background =element_rect(fill=‚Äúlightgray‚Äù),\naxis.title.x = element_text(angle = 0,\nsize = rel(1.5),\nmargin = margin(10,0,0,0)),\naxis.title.y = element_text(angle = 0,\nsize = rel(1.5),\nmargin = margin(0,10,0,0))\n)\n)\n``\nLet‚Äôs analyze the `spotifyall` data:\n```{r}\nspotify&lt;- read_csv(https://bcdanl.github.io/data/spotify_all.csv)\n```\n```{r}\n#| results: asis\nrmarkdown::paged_table(spotify)\n```"
  },
  {
    "objectID": "spotifyall.html",
    "href": "spotifyall.html",
    "title": "spotifyall",
    "section": "",
    "text": "---\ntitle: ‚Äúspotifyall‚Äù\nauthor: ‚ÄúJordan Alfano‚Äù\ndate: ‚Äú2023-12-08‚Äù\ncategories: [spotifyall, code, analysis]\nimage: ‚Äúimage.png‚Äù\nexecute:\nwarning: false\nmessage: false\ntoc: true\n---\n```{r}\n#| include: false\nlibrary(knitr)\nlibrary(rmarkdown)\nlibrary(tidyverse)\nlibrary(skimr)\nlibrary(ggthemes)\nlibrary(hrbrthemes)\ntheme_set(theme_ipsum()+\ntheme(strip.background =element_rect(fill=‚Äúlightgray‚Äù),\naxis.title.x = element_text(angle = 0,\nsize = rel(1.5),\nmargin = margin(10,0,0,0)),\naxis.title.y = element_text(angle = 0,\nsize = rel(1.5),\nmargin = margin(0,10,0,0))\n)\n)\n``\nLet‚Äôs analyze the `spotifyall` data:\n```{r}\nspotifyall&lt;- read_csv(https://bcdanl.github.io/data/spotify_all.csv)\n```\n```{r}\n#| results: asis\nrmarkdown::paged_table(spotifyall)\n```"
  },
  {
    "objectID": "data200-hw5-Jordan-Alfano.html",
    "href": "data200-hw5-Jordan-Alfano.html",
    "title": "danl200-hw5-alfano-jordan",
    "section": "",
    "text": "[https://github.com/jca100/jca100.github.io(https://github.com/jca100/jca100.github.io)\nDANL 200: Homework Assignment 5 PUBLISHED December 4, 2023\nSubmit the danl200-hw5-YOUR_LAST_NAME-YOUR_FIRST_NAME.qmd file to Brightspace for Q1a and Question 2 in Homework Assignment 5. Rendering the file, danl200-hw5-YOUR_LAST_NAME-YOUR_FIRST_NAME.qmd, should not give any errors. Due is December 11, 11:59 P.M.\nQuestion 1. Personal Website on GitHub Q1a. Provide a link for your GihtHub repository, https://github.com/YOUR_GITHUB_USERNAME/YOUR_GITHUB_USERNAME.github.io\nhttps://github.com/jca100/jca100.github.io\nAdd a URL for your website (https://YOUR_GITHUB_USERNAME.github.io/) in the About section in your GihtHub repository webpage by clicking the setting. For example, the below shows the :\nQ1b. Make sure that your GitHub repository, named YOUR_GITHUB_USERNAME.github.io, is set to public.\nUpdate your website at https://YOUR_GITHUB_USERNAME.github.io/index.html to:\nInclude links to (1) your LinkedIn page, (2) GitHub page (https://github.com/YOUR_GITHUB_USERNAME), and (3) a PDF file of your R√®sume (https://YOUR_GITHUB_USERNAME.github.io/YOUR_RESUME.pdf). Offer a description of yourself, detailing your education background and professional experience. Display your own profile picture with your face, not the one shown below.\nQ1c. Change the title of your blog.\nThat is, to replace Insightful Analytics with your own blog name. Remove the blog posts Post With Code, Starwars, and Beer Markets.\nRevise the Welcome To My Blog post.\nPost three different blog articles based on data analysis using the following three CSV files:\nhttps://bcdanl.github.io/data/DOHMH_NYC_Restaurant_Inspection.csv https://bcdanl.github.io/data/spotify_all.csv https://bcdanl.github.io/data/beer_markets.csv\nMake sure that each blog post has categories and is associated with a proper image file that is displayed as a thumbnail at the list page of the blog. Make sure that each blog post uses emojis properly. (E.g., üòÑ üç∫ üé∂ üçï)\nMake sure that each blog post includes its thumbnail image and at least three ggplot figures. You can refer to the previous DANL 200 Homework Assignments and Exams for your blog posts.\nQuestion 2.\nNFL in 2022 Add a blog post with your answers for Question 2 to your website (https://YOUR_GITHUB_USERNAME.github.io/).\nMake sure that your blog post for Question 2 includes all the questionnaires and your answers to them. Make sure that your blog post for Question 2 has a section for each sub-question (e.g., Q2a, Q2b) in Question 2, so that the Table of Contents display the section for each questionnaire.\nThe following is the data.frame for Question 2. NFL2022_stuffs &lt;- read_csv(‚Äòhttps://bcdanl.github.io/data/NFL2022_stuffs.csv‚Äô)\nplay_id  game_id  drive  week  posteam  qtr  down  half_seconds_remaining  pass  wp  1 2022_01_BAL_NYJ NA 1 NA 1 NA 1800 0 5.462618e-01 43 2022_01_BAL_NYJ 1 1 NYJ 1 NA 1800 0 5.462618e-01 68 2022_01_BAL_NYJ 1 1 NYJ 1 1 1796 0 5.469690e-01 89 2022_01_BAL_NYJ 1 1 NYJ 1 1 1769 1 5.725734e-01 115 2022_01_BAL_NYJ 1 1 NYJ 1 2 1765 0 5.545366e-01 136 2022_01_BAL_NYJ 1 1 NYJ 1 3 1741 1 5.401673e-01 172 2022_01_BAL_NYJ 1 1 NYJ 1 4 1733 0 4.880532e-01 202 2022_01_BAL_NYJ 2 1 BAL 1 1 1722 1 4.958201e-01 230 2022_01_BAL_NYJ 2 1 BAL 1 2 1701 1 4.965942e-01 254 2022_01_BAL_NYJ 2 1 BAL 1 3 1661 0 4.987317e-01 ‚Ä¶ 1-10 of 10,000 rows NFL2022_stuffs is the data.frame that contains information about NFL games in year 2022, in which the unit of observation is a single play for each drive in a NFL game. Variable description play_id: Numeric play identifier that when used with game_id and drive provides the unique identifier for a single play game_id: Ten digit identifier for NFL game. drive: Numeric drive number in the game. week: Season week. posteam: String abbreviation for the team with possession. qtr: Quarter of the game (5 is overtime). half_seconds_remaining: Numeric seconds remaining in the half. down: The down for the given play. Basically you get four attempts (aka downs) to move the ball 10 yards (by either running with it or passing it). If you make 10 yards then you get another set of four downs. pass: Binary indicator if the play was a pass play. wp: Estimated winning probability for the posteam given the current situation at the start of the given play.\nQ2a. In data.frame, NFL2022_stuffs, remove observations for which values of posteam is missing.\nAnswer: # Assuming NFL2022_stuffs is your data frame\nNFL2022_stuffs &lt;- na.omit(NFL2022_stuffs[, !is.na(NFL2022_stuffs$posteam)])\nQ2b. Summarize the mean value of pass for each posteam when all the following conditions hold: wp is greater than 20% and less than 75%; down is less than or equal to 2; and half_seconds_remaining is greater than 120.\nAnswer:\nlibrary(dplyr)\nresult &lt;- NFL2022_stuffs %&gt;%\nfilter(wp &gt; 0.20 & wp &lt; 0.75 & down &lt;= 2 & half_seconds_remaining &gt; 120) %&gt;%\ngroup_by(posteam) %&gt;%\nsummarize(mean_pass = mean(pass, na.rm = TRUE))\nQ2c. Provide both (1) a ggplot code with geom_point() using the resulting data.frame in Q2b and (2) a simple comments to describe the mean value of pass for each posteam. In the ggplot, reorder the posteam categories based on the mean value of pass in ascending or in descending order.\nAnswer:\nlibrary(ggplot2)\nresult$posteam &lt;- factor(result$posteam, levels = result$posteam[order(result$mean_pass)])\nggplot(result, aes(x = posteam, y = mean_pass)) +\ngeom_point() +\nlabs(title = ‚ÄúMean Value of pass for each posteam‚Äù,\nx = ‚ÄúPosteam‚Äù,\ny = ‚ÄúMean Pass Value‚Äù)\nQ2d. Consider the following data.frame, NFL2022_epa: NFL2022_epa &lt;- read_csv(‚Äòhttps://bcdanl.github.io/data/NFL2022_epa.csv‚Äô)\nCreate the data.frame, NFL2022_stuffs_EPA, that includes\nAll the variables in the data.frame, NFL2022_stuffs; The variables, passer, receiver, and epa, from the data.frame, NFL2022_epa. by joining the two data.frames. In the resulting data.frame, NFL2022_stuffs_EPA, remove observations with NA in passer.\nAnswer:\nlibrary(dplyr)\nNFL2022_stuffs_EPA &lt;- inner_join(NFL2022_stuffs, NFL2022_epa[, c(‚Äúpasser‚Äù, ‚Äúreceiver‚Äù, ‚Äúepa‚Äù)], by = ‚Äúpasser‚Äù)\nNFL2022_stuffs_EPA &lt;- NFL2022_stuffs_EPA[complete.cases(NFL2022_stuffs_EPA$passer), ]\nQ2e. Provide both (1) a single ggplot and (2) a simple comment to describe the NFL weekly trend of weekly mean value of epa for each of the following two passers, ‚ÄúJ.Allen‚Äù ‚ÄúP.Mahomes‚Äù\nAnswer: library(ggplot2)\nggplot(NFL2022_stuffs_EPA, aes(x = week, y = epa, color = passer)) +\ngeom_line() +\ngeom_point() +\nlabs(title = ‚ÄúNFL Weekly Trend of Mean EPA for J.Allen and P.Mahomes‚Äù,\nx = ‚ÄúWeek‚Äù,\ny = ‚ÄúMean EPA‚Äù) +\ncolor(values = c(‚ÄúJ.Allen‚Äù = ‚Äúblue‚Äù, ‚ÄúP.Mahomes‚Äù = ‚Äúred‚Äù))\nQ2f. Calculate the difference between the mean value of epa for ‚ÄúJ.Allen‚Äù the mean value of epa for ‚ÄúP.Mahomes‚Äù for each value of week.\nAnswer:\nlibrary(dplyr)\ngroup_by(week) %&gt;%\nsummarize(mean_epa_diff = mean(epa[passer == ‚ÄúJ.Allen‚Äù], na.rm = TRUE) -\nmean(epa[passer == ‚ÄúP.Mahomes‚Äù], na.rm = TRUE))\nQ2g. Summarize the resulting data.frame in Q2d, with the following four variables:\nposteam: String abbreviation for the team with possession. passer: Name of the player who passed a ball to a receiver by initially taking a three-step drop, and backpedaling into the pocket to make a pass. (Mostly, they are quarterbacks.) mean_epa: Mean value of epa in 2022 for each passer n_pass: Number of observations for each passer Then find the top 10 NFL passers in 2022 in terms of the mean value of epa, conditioning that n_pass must be greater than or equal to the third quantile level of n_pass.\nAnswer:\nlibrary(dplyr)\nsummary_data &lt;- NFL2022_stuffs_EPA %&gt;%\ngroup_by(posteam, passer) %&gt;%\nsummarize(mean_epa = mean(epa, na.rm = TRUE),\nn_pass = n())\nquantile_threshold &lt;- quantile(summary_data$n_pass, 0.75)\ntop_passers &lt;- summary_data %&gt;%\nfilter(n_pass &gt;= quantile_threshold) %&gt;%\ntop_n(10, wt = mean_epa)\ntop_passers"
  },
  {
    "objectID": "quarto-template (2).html",
    "href": "quarto-template (2).html",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "",
    "text": "day_wise &lt;- read_csv('https://jem10126.github.io/day_wise.csv')\nnvars &lt;- format(round(ncol(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\") \nnobs &lt;- format(round(nrow(day_wise), 0), \n                nsmall=0, \n                big.mark=\",\")\nThe number of variables is 12; the number of observations is 188."
  },
  {
    "objectID": "quarto-template (2).html#data-summary",
    "href": "quarto-template (2).html#data-summary",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.1 Data Summary",
    "text": "2.1 Data Summary\n\nSummary statistics (Use skimr::skim())"
  },
  {
    "objectID": "quarto-template (2).html#data-visualization",
    "href": "quarto-template (2).html#data-visualization",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "1.1 Data Visualization",
    "text": "1.1 Data Visualization\n\nday_wise %&gt;% \n  ggplot(aes(x = log(Deaths), \n             y = log(Recovered))) + \n  geom_point(alpha = .1, color = 'purple') +\n  geom_smooth(method = lm, se = F) +\n  theme_bw() +\n  theme(legend.position = 'top')\n\n\n\n\n\n(skimr::skim(day_wise))\n\n\nData summary\n\n\nName\nday_wise\n\n\nNumber of rows\n188\n\n\nNumber of columns\n12\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nDate\n1\n\n\nnumeric\n11\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: Date\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmin\nmax\nmedian\nn_unique\n\n\n\n\nDate\n0\n1\n2020-01-22\n2020-07-27\n2020-04-24\n188\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nConfirmed\n0\n1\n4406960.01\n4757988.32\n555.00\n112191.00\n2848733.00\n7422045.50\n16480485.00\n‚ñá‚ñÉ‚ñÇ‚ñÇ‚ñÅ\n\n\nDeaths\n0\n1\n230770.76\n217929.09\n17.00\n3935.00\n204190.00\n418634.50\n654036.00\n‚ñá‚ñÇ‚ñÉ‚ñÉ‚ñÇ\n\n\nRecovered\n0\n1\n2066001.22\n2627976.39\n28.00\n60441.25\n784784.00\n3416395.75\n9468087.00\n‚ñá‚ñÇ‚ñÅ‚ñÅ‚ñÅ\n\n\nActive\n0\n1\n2110188.03\n1969670.45\n510.00\n58641.75\n1859759.00\n3587015.25\n6358362.00\n‚ñá‚ñÉ‚ñÉ‚ñÇ‚ñÇ\n\n\nNew cases\n0\n1\n87771.02\n75295.29\n0.00\n5568.50\n81114.00\n131502.50\n282756.00\n‚ñá‚ñá‚ñÉ‚ñÇ‚ñÇ\n\n\nNew deaths\n0\n1\n3478.82\n2537.74\n0.00\n250.75\n4116.00\n5346.00\n9966.00\n‚ñá‚ñÉ‚ñá‚ñÉ‚ñÅ\n\n\nNew recovered\n0\n1\n50362.02\n56090.89\n0.00\n2488.25\n30991.50\n79706.25\n284394.00\n‚ñá‚ñÇ‚ñÇ‚ñÅ‚ñÅ\n\n\nDeaths / 100 Cases\n0\n1\n4.86\n1.58\n2.04\n3.51\n4.85\n6.30\n7.18\n‚ñÖ‚ñÖ‚ñÜ‚ñÖ‚ñá\n\n\nRecovered / 100 Cases\n0\n1\n34.34\n16.21\n1.71\n22.78\n35.68\n48.95\n57.45\n‚ñÉ‚ñÉ‚ñÜ‚ñÖ‚ñá\n\n\nDeaths / 100 Recovered\n0\n1\n22.10\n22.57\n6.26\n9.65\n15.38\n25.34\n134.43\n‚ñá‚ñÅ‚ñÅ‚ñÅ‚ñÅ\n\n\nNo.¬†of countries\n0\n1\n144.35\n65.18\n6.00\n101.25\n184.00\n187.00\n187.00\n‚ñÇ‚ñÅ‚ñÅ‚ñÅ‚ñá"
  },
  {
    "objectID": "quarto-template (2).html#data-transformation",
    "href": "quarto-template (2).html#data-transformation",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "1.2 Data Transformation",
    "text": "1.2 Data Transformation\n\nday_wise &lt;- day_wise %&gt;% \n  group_by(Deaths, Recovered) %&gt;% \n  summarise(Recovered_tot = sum(Recovered, na.rm = T),\n            Deaths_mean = round(mean(Deaths, na.rm = T), 2),\n            .groups = \"drop\")"
  },
  {
    "objectID": "quarto-template (2).html#analysis",
    "href": "quarto-template (2).html#analysis",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.4 Analysis",
    "text": "2.4 Analysis"
  },
  {
    "objectID": "quarto-template (2).html#quotes",
    "href": "quarto-template (2).html#quotes",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.5 Quotes",
    "text": "2.5 Quotes\n\nQuote with &gt;\n\n\n‚ÄúThe truth is rarely pure and never simple.‚Äù\n‚Äî Oscar Wilde"
  },
  {
    "objectID": "quarto-template (2).html#inserting-figures",
    "href": "quarto-template (2).html#inserting-figures",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.6 Inserting Figures",
    "text": "2.6 Inserting Figures\nFor a demonstration of a DANL tiger, see Figure¬†1.\n\n\n\n\n\nFigure¬†1: DANL Tiger"
  },
  {
    "objectID": "quarto-template (2).html#inserting-a-html-page",
    "href": "quarto-template (2).html#inserting-a-html-page",
    "title": "DANL 200: Introduction to Data AnalyticsProject",
    "section": "2.7 Inserting a HTML page",
    "text": "2.7 Inserting a HTML page"
  },
  {
    "objectID": "project.html#analysis",
    "href": "project.html#analysis",
    "title": "DANL Project",
    "section": "0.1 Analysis",
    "text": "0.1 Analysis\nAs seen across the world, so many people were pessimistic about the pandemic. Including my group members and I. In the end, there were more people who were saved and beat the virus compared to the unfortunate ones who did not make it. There is no doubt that the world has been changed but it is relevant to know that there were more people being helped and cured compared to the amount of people that were dying because of this deadly pandemic."
  },
  {
    "objectID": "project.html#quotes",
    "href": "project.html#quotes",
    "title": "DANL Project",
    "section": "0.2 Quotes",
    "text": "0.2 Quotes\n\nQuote with &gt;\n\n\n‚ÄúThe truth is rarely pure and never simple.‚Äù\n‚Äî Oscar Wilde"
  },
  {
    "objectID": "project.html#inserting-figures",
    "href": "project.html#inserting-figures",
    "title": "DANL Project",
    "section": "0.3 Inserting Figures",
    "text": "0.3 Inserting Figures\nFor a demonstration of a DANL tiger, see ?@fig-tiger."
  }
]